{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cellari_U-Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDr8hI9cgMdT"
      },
      "source": [
        "Cellario U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-RZ-1r6OzYj"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJCHiX8SOqCc",
        "outputId": "db5f4742-d66f-47c6-ad3e-809f4020ce4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSBy4v22OsCJ"
      },
      "source": [
        "#!ls drive/'My Drive'\n",
        "!ls drive/'My Drive/Gland_dataset' &> /dev/null\n",
        "\n",
        "drive_path = 'drive/My Drive/Cellari_project'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av7ma02UPvPO",
        "outputId": "2a5da9f6-84cd-4b97-97c8-d2b771ad6396",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#seperate the data into training and test and annotated data and load it\n",
        "#60 test A images\n",
        "# 20 test B images\n",
        "# 85 train images\n",
        "\n",
        "test_images_A = [imread(drive_path +'/Gland_dataset/testA_{}.bmp'.format(i)) for i in range(1,61)] \n",
        "test_images_B = [imread(drive_path +'/Gland_dataset/testB_{}.bmp'.format(i)) for i in range(1,21)] \n",
        "test_images = test_images_A + test_images_B\n",
        "print(\"done with test images\")\n",
        "\n",
        "test_images_A_anno = [imread(drive_path +'/Gland_dataset/testA_{}_anno.bmp'.format(i)) for i in range(1,61)] \n",
        "test_images_B_anno = [imread(drive_path +'/Gland_dataset/testB_{}_anno.bmp'.format(i)) for i in range(1,21)]   \n",
        "test_images_anno = test_images_A_anno + test_images_B_anno \n",
        "print(\"done with test images annotated\")\n",
        "\n",
        "train_images = [imread(drive_path +'/Gland_dataset/train_{}.bmp'.format(i)) for i in range(1,86)] \n",
        "print(\"done with train images\")\n",
        "train_images_anno = [imread(drive_path +'/Gland_dataset/train_{}_anno.bmp'.format(i)) for i in range(1,86)]\n",
        "print(\"done with train images annotated\")\n",
        "\n",
        "print(\"The training set contains {} images\".format(len(train_images)))\n",
        "print(\"The test set contains {} images\".format(len(test_images )))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done with test images\n",
            "done with test images annotated\n",
            "done with train images\n",
            "done with train images annotated\n",
            "The training set contains 85 images\n",
            "The test set contains 80 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy6ootuguyAt"
      },
      "source": [
        "#reshaped image for to make the convolutions easier\n",
        "test_images = np.array(test_images)\n",
        "for i in range(0,len(test_images)):\n",
        "  test_images[i] = resize(test_images[i], output_shape=(522,522), mode='reflect', anti_aliasing=True)\n",
        "  #test_images_mean = np.mean(test_images[i],axis=(0,1))\n",
        "  #test_images[i] = (test_images[i] - test_images[i].mean() )/test_images[i].std()\n",
        "  \n",
        "  \n",
        "  test_images_anno[i] = resize(test_images_anno[i], output_shape=(522,522), mode='reflect', anti_aliasing=True)\n",
        "  \n",
        "for i in range(0,len(train_images)):\n",
        "  train_images[i] = resize(train_images[i], output_shape=(522,522), mode='reflect', anti_aliasing=True)\n",
        "  train_images_anno[i] = resize(train_images_anno[i], output_shape=(522,522), mode='reflect', anti_aliasing=True)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzoG1ilrkZQ6",
        "outputId": "66227fb9-7235-4d8d-8eff-3f45e7faa821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(test_images[0][:][:][0])\n",
        "\n",
        "test =test_images[0][:][:][0]\n",
        "print(test.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.86196347  0.43647086  0.60580816]\n",
            " [ 0.49659997 -0.19417281  0.52658541]\n",
            " [-0.35185351 -1.38061522  0.18875472]\n",
            " ...\n",
            " [ 0.77438067  0.18775257  0.6769082 ]\n",
            " [-0.10927999 -0.95781259  0.46147191]\n",
            " [ 0.35809203 -0.09155773  0.2111449 ]]\n",
            "(522, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxdPb9dKy0TP"
      },
      "source": [
        "#reshaped image for to make the convolutions easier\n",
        "test_images = np.array(test_images)\n",
        "for i in range(0,len(test_images)):\n",
        "  test_images[i] = resize(test_images[i], output_shape=(522,522), mode='reflect', anti_aliasing=True)\n",
        "  test_images_mean = np.mean(test_images[i],axis=(0,1))\n",
        "  test_images[i] = (test_images[i] - test_images[i].mean() )/test_images[i].std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJlTfDAxAKb3"
      },
      "source": [
        "# Plot of the first image\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(train_images[0])\n",
        "plt.title(\"Train image 1\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(train_images_anno[0])\n",
        "plt.title(\"Annotation for train image 1 \")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKXZhNVW1Fp3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDMek8_31Ysa"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyh-nUH51GmP"
      },
      "source": [
        "The U-Net architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lG-eDhe1KTf"
      },
      "source": [
        "# Load functions\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, Conv2d, Dropout, MaxPool2d, BatchNorm1d\n",
        "from torch.nn.functional import relu, sigmoid, tanh, softmax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2duJLeA1lcX"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"Running GPU.\") if use_cuda else print(\"No GPU available.\")\n",
        "\n",
        "\n",
        "def get_variable(x):\n",
        "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
        "    if use_cuda:\n",
        "        return x.cuda()\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_numpy(x):\n",
        "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
        "    if use_cuda:\n",
        "        return x.cpu().data.numpy()\n",
        "    return x.data.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53fS91nx1_I2"
      },
      "source": [
        "\n",
        "def double_conv(channel_in, channel_out):\n",
        "  conv = nn.Sequential(\n",
        "      nn.Conv2d(channel_in, channel_out, kernel_size = 3),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(channel_out, channel_out, kernel_size = 3),\n",
        "      nn.ReLU(inplace=True)\n",
        "  )\n",
        "  return conv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class U_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(U_Net, self).__init__()\n",
        " \n",
        "        self.max_pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        #convolute the image down \n",
        "        self.conv_down_1 = double_conv(3, 64)\n",
        "        self.conv_down_2 = double_conv(64, 128)\n",
        "        self.conv_down_3 = double_conv(128, 256)\n",
        "        self.conv_down_4 = double_conv(256, 512)\n",
        "        self.conv_down_5 = double_conv(512, 1024)\n",
        "\n",
        "        #convolute the image up\n",
        "        self.trans_up_1 = nn.ConvTranspose2d(in_channels = 1024, out_channels = 512, kernel_size = 2, stride = 2)\n",
        "        self.conv_up_1 = double_conv(1024, 512)\n",
        "\n",
        "        self.trans_up_2 = nn.ConvTranspose2d(in_channels = 512, out_channels = 256, kernel_size = 2, stride = 2)\n",
        "        self.conv_up_2 = double_conv(512, 256)\n",
        "\n",
        "        self.trans_up_3 = nn.ConvTranspose2d(in_channels = 256, out_channels = 128, kernel_size = 2, stride = 2)\n",
        "        self.conv_up_3 = double_conv(256, 128)\n",
        "\n",
        "        self.trans_up_4 = nn.ConvTranspose2d(in_channels = 128, out_channels = 64, kernel_size = 2, stride = 2)\n",
        "        self.conv_up_4 = double_conv(128, 64)\n",
        "\n",
        "        self.out = nn.Conv2d(in_channels = 64, out_channels = 2, kernel_size= 1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        x1 = self.conv_down_1(img)\n",
        "        print(x1.size())\n",
        "        x2 = self.max_pool(x1)\n",
        "        x3 = self.conv_down_2(x2)\n",
        "        x4 = self.max_pool(x3)\n",
        "        x5 = self.conv_down_3(x4)\n",
        "        x6 = self.max_pool(x5)\n",
        "        x7 = self.conv_down_4(x6)\n",
        "        x8 = self.max_pool(x7)\n",
        "        x9 = self.conv_down_5(x8)\n",
        "        print(x9.size())\n",
        "\n",
        "\n",
        "        x10 = self.trans_up_1(x9)\n",
        "        crop1 = image_cropping(x7,x10)\n",
        "        x11 = self.conv_up_1(torch.cat[x10,crop1]) \n",
        "\n",
        "        x12 = self.trans_up_2(x11)\n",
        "        crop2 = image_cropping(x5,x12)\n",
        "        x13 = self.conv_up_2(torch.cat[x12,crop2]) \n",
        "\n",
        "        x14 = self.trans_up_3(x13)\n",
        "        crop3 = image_cropping(x3,x14)\n",
        "        x15 = self.conv_up_3(torch.cat[x14,crop3]) \n",
        "\n",
        "        x16 = self.trans_up_4(x15)\n",
        "        crop4 = image_cropping(x1,x16)\n",
        "        x17 = self.conv_up_4(torch.cat[x16,crop4]) \n",
        "\n",
        "        output = self.out(x17)\n",
        "        print(x10.size())\n",
        "        print(x7.size())\n",
        "        print(crop1.size())\n",
        "\n",
        "\n",
        "        return output\n",
        "  \n",
        "\n",
        "  \n",
        "net = U_Net()\n",
        "net = net.cuda()\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YncQ838RHyi"
      },
      "source": [
        "\n",
        "# dummy data\n",
        "rand_img = torch.rand((1,3,522,522))\n",
        "rand_img = rand_img.cuda()\n",
        "\n",
        "# test the forward pass\n",
        "my_nn = U_Net()\n",
        "my_nn = my_nn.cuda()\n",
        "result = my_nn(img = rand_img)\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6GJLT2fWM8v"
      },
      "source": [
        "def image_cropping(img, desired_img):\n",
        "  desired_dimensions = desired_img.size()[2]\n",
        "  current_dimensions = img.size()[2]\n",
        "  difference = (current_dimensions - desired_dimensions)//2\n",
        "  start_slice = difference\n",
        "  end_slice = current_dimensions-difference\n",
        "  img = img[:, :, start_slice:end_slice, start_slice:end_slice]\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inlRew-qijMH"
      },
      "source": [
        "rand_img = torch.rand((1,3,138,138))\n",
        "rand_img2 = torch.rand((1,3,104,104))\n",
        "img = image_cropping(rand_img,rand_img2)\n",
        "print(img.size())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}